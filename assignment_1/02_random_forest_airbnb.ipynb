{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Random Forest      \n",
    "                                     \n",
    "Topics covered:                     \n",
    "   - Data cleaning & refactoring & feature engineering in a separate file            \n",
    "   - Run random forest  \n",
    "     - set mytr                      \n",
    "     - autotune                       \n",
    "   - Understanding RF output:        \n",
    "     - variable importance plots:    \n",
    "       - all, top 10 and permutation importance for categorical features      \n",
    "     - partial dependence plot       \n",
    "     - sub-sample analysis    \n",
    "     - SHAP values\n",
    "   - \"Horse-race\": model comparison  \n",
    "     - OLS, Lasso, CART, RF and XGBoost model          \n",
    "                                \n",
    "Case studies:                  \n",
    "  - CH16A Predicting apartment prices with random forest  \n",
    "                                \n",
    "Dataset:\n",
    "\n",
    "    airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mizani.formatters import percent_format\n",
    "from patsy import dmatrices\n",
    "from plotnine import *\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(\n",
    "    n_bathrooms=lambda x: x[\"n_bathrooms\"].fillna(np.median(x[\"n_bathrooms\"].dropna())),\n",
    "    n_beds=lambda x: np.where(x[\"n_beds\"].isnull(), x[\"n_accommodates\"], x[\"n_beds\"]),\n",
    "    f_bathroom=lambda x: x[\"f_bathroom\"].fillna(1),\n",
    "    f_minimum_nights=lambda x: x[\"f_minimum_nights\"].fillna(1),\n",
    "    f_number_of_reviews=lambda x: x[\"f_number_of_reviews\"].fillna(1),\n",
    "    ln_beds=lambda x: x[\"ln_beds\"].fillna(0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I\n",
    "### Loading and preparing data \n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/airbnb_madrid_workfile_adj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample definition and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on normal apartments, n<8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[lambda x: x[\"n_accommodates\"] < 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy a variable - purpose later, see at variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(n_accommodates_copy=data.n_accommodates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usd_price_day</th>\n",
       "      <th>p_host_response_rate</th>\n",
       "      <th>n_accommodates</th>\n",
       "      <th>n_bathrooms</th>\n",
       "      <th>n_review_scores_rating</th>\n",
       "      <th>n_number_of_reviews</th>\n",
       "      <th>n_reviews_per_month</th>\n",
       "      <th>n_minimum_nights</th>\n",
       "      <th>n_beds</th>\n",
       "      <th>n_days_since</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_review_scores_rating</th>\n",
       "      <th>flag_reviews_per_month</th>\n",
       "      <th>flag_n_number_of_reviews</th>\n",
       "      <th>ln_days_since</th>\n",
       "      <th>ln_days_since2</th>\n",
       "      <th>ln_days_since3</th>\n",
       "      <th>n_days_since2</th>\n",
       "      <th>n_days_since3</th>\n",
       "      <th>ln_review_scores_rating</th>\n",
       "      <th>n_accommodates_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.0</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.0</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>2.023300e+04</td>\n",
       "      <td>2.023300e+04</td>\n",
       "      <td>20233.000000</td>\n",
       "      <td>20233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>117.980626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.019473</td>\n",
       "      <td>1.253398</td>\n",
       "      <td>4.669453</td>\n",
       "      <td>53.026442</td>\n",
       "      <td>1.940280</td>\n",
       "      <td>7.060940</td>\n",
       "      <td>1.829931</td>\n",
       "      <td>6.282932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170415</td>\n",
       "      <td>0.170415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.282932</td>\n",
       "      <td>40.894425</td>\n",
       "      <td>273.354686</td>\n",
       "      <td>1.725053e+06</td>\n",
       "      <td>4.461300e+09</td>\n",
       "      <td>1.534179</td>\n",
       "      <td>3.019473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>91.768908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.521987</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>0.427763</td>\n",
       "      <td>93.815632</td>\n",
       "      <td>1.826741</td>\n",
       "      <td>17.356968</td>\n",
       "      <td>1.243126</td>\n",
       "      <td>1.191328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376006</td>\n",
       "      <td>0.376006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191328</td>\n",
       "      <td>13.978358</td>\n",
       "      <td>131.588942</td>\n",
       "      <td>3.234207e+06</td>\n",
       "      <td>1.158312e+10</td>\n",
       "      <td>0.135768</td>\n",
       "      <td>1.521987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.610000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.710427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.710427</td>\n",
       "      <td>32.608977</td>\n",
       "      <td>186.211182</td>\n",
       "      <td>9.060100e+04</td>\n",
       "      <td>2.727090e+07</td>\n",
       "      <td>1.528228</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.388561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.388561</td>\n",
       "      <td>40.813717</td>\n",
       "      <td>260.740936</td>\n",
       "      <td>3.528360e+05</td>\n",
       "      <td>2.095846e+08</td>\n",
       "      <td>1.560248</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>147.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.023759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.023759</td>\n",
       "      <td>49.333190</td>\n",
       "      <td>346.504434</td>\n",
       "      <td>1.258884e+06</td>\n",
       "      <td>1.412468e+09</td>\n",
       "      <td>1.585145</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1092.000000</td>\n",
       "      <td>41.220000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.546364</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.546364</td>\n",
       "      <td>73.040330</td>\n",
       "      <td>624.229217</td>\n",
       "      <td>2.649161e+07</td>\n",
       "      <td>1.363523e+11</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       usd_price_day  p_host_response_rate  n_accommodates   n_bathrooms  \\\n",
       "count   20233.000000               20233.0    20233.000000  20233.000000   \n",
       "mean      117.980626                   0.0        3.019473      1.253398   \n",
       "std        91.768908                   0.0        1.521987      0.595112   \n",
       "min         1.000000                   0.0        1.000000      0.000000   \n",
       "25%        60.000000                   0.0        2.000000      1.000000   \n",
       "50%       100.000000                   0.0        3.000000      1.000000   \n",
       "75%       147.000000                   0.0        4.000000      1.000000   \n",
       "max       999.000000                   0.0        7.000000     12.000000   \n",
       "\n",
       "       n_review_scores_rating  n_number_of_reviews  n_reviews_per_month  \\\n",
       "count            20233.000000         20233.000000         20233.000000   \n",
       "mean                 4.669453            53.026442             1.940280   \n",
       "std                  0.427763            93.815632             1.826741   \n",
       "min                  1.000000             0.000000             0.010000   \n",
       "25%                  4.610000             2.000000             0.730000   \n",
       "50%                  4.760000            15.000000             1.460000   \n",
       "75%                  4.880000            61.000000             2.540000   \n",
       "max                  5.000000          1092.000000            41.220000   \n",
       "\n",
       "       n_minimum_nights        n_beds  n_days_since  ...  \\\n",
       "count      20233.000000  20233.000000  20233.000000  ...   \n",
       "mean           7.060940      1.829931      6.282932  ...   \n",
       "std           17.356968      1.243126      1.191328  ...   \n",
       "min            1.000000      0.000000      0.000000  ...   \n",
       "25%            1.000000      1.000000      5.710427  ...   \n",
       "50%            2.000000      2.000000      6.388561  ...   \n",
       "75%            3.000000      2.000000      7.023759  ...   \n",
       "max          364.000000     40.000000      8.546364  ...   \n",
       "\n",
       "       flag_review_scores_rating  flag_reviews_per_month  \\\n",
       "count               20233.000000            20233.000000   \n",
       "mean                    0.170415                0.170415   \n",
       "std                     0.376006                0.376006   \n",
       "min                     0.000000                0.000000   \n",
       "25%                     0.000000                0.000000   \n",
       "50%                     0.000000                0.000000   \n",
       "75%                     0.000000                0.000000   \n",
       "max                     1.000000                1.000000   \n",
       "\n",
       "       flag_n_number_of_reviews  ln_days_since  ln_days_since2  \\\n",
       "count                   20233.0   20233.000000    20233.000000   \n",
       "mean                        0.0       6.282932       40.894425   \n",
       "std                         0.0       1.191328       13.978358   \n",
       "min                         0.0       0.000000        0.000000   \n",
       "25%                         0.0       5.710427       32.608977   \n",
       "50%                         0.0       6.388561       40.813717   \n",
       "75%                         0.0       7.023759       49.333190   \n",
       "max                         0.0       8.546364       73.040330   \n",
       "\n",
       "       ln_days_since3  n_days_since2  n_days_since3  ln_review_scores_rating  \\\n",
       "count    20233.000000   2.023300e+04   2.023300e+04             20233.000000   \n",
       "mean       273.354686   1.725053e+06   4.461300e+09                 1.534179   \n",
       "std        131.588942   3.234207e+06   1.158312e+10                 0.135768   \n",
       "min          0.000000   0.000000e+00   0.000000e+00                 0.000000   \n",
       "25%        186.211182   9.060100e+04   2.727090e+07                 1.528228   \n",
       "50%        260.740936   3.528360e+05   2.095846e+08                 1.560248   \n",
       "75%        346.504434   1.258884e+06   1.412468e+09                 1.585145   \n",
       "max        624.229217   2.649161e+07   1.363523e+11                 1.609438   \n",
       "\n",
       "       n_accommodates_copy  \n",
       "count         20233.000000  \n",
       "mean              3.019473  \n",
       "std               1.521987  \n",
       "min               1.000000  \n",
       "25%               2.000000  \n",
       "50%               3.000000  \n",
       "75%               4.000000  \n",
       "max               7.000000  \n",
       "\n",
       "[8 rows x 217 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20233.000000\n",
       "mean       117.980626\n",
       "std         91.768908\n",
       "min          1.000000\n",
       "25%         60.000000\n",
       "50%        100.000000\n",
       "75%        147.000000\n",
       "max        999.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_room_type\n",
       "Entire          13805\n",
       "Private room     5926\n",
       "Shared room       260\n",
       "Unknown           242\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.f_room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_property_type\n",
       "Apartment              18087\n",
       "House                    995\n",
       "Hotel/Serviced Stay      610\n",
       "Hostel                   268\n",
       "Traditional Stay         191\n",
       "Unknown                   54\n",
       "Alternative Stay          28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.f_property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_number_of_reviews\n",
       "[1, 51)       11039\n",
       "[51, 1092)     5745\n",
       "[0, 1)         3448\n",
       "99                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.f_number_of_reviews.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and holdout samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is where we do it all, incl CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_holdout = train_test_split(data, train_size=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14163, 227), (6070, 227))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_holdout.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Variables inc neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_vars = [\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"n_days_since\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"f_bathroom\",\n",
    "    #\"f_cancellation_policy\",\n",
    "    #\"f_bed_type\",\n",
    "    \"f_neighbourhood_cleansed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"n_number_of_reviews\",\n",
    "    \"flag_n_number_of_reviews\",\n",
    "    \"n_review_scores_rating\",\n",
    "    \"flag_review_scores_rating\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = [col for col in data if col.startswith(\"d_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions for the LASSO from lecture 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [\n",
    "    \"n_accommodates:f_property_type\",\n",
    "    \"f_room_type:f_property_type\",\n",
    "    \"f_room_type:d_familykidfriendly\",\n",
    "    \"d_airconditioning:f_property_type\",\n",
    "    \"d_cats:f_property_type\",\n",
    "    \"d_dogs:f_property_type\",\n",
    "]\n",
    "# with boroughs\n",
    "X2 = [\n",
    "    \"f_property_type:f_neighbourhood_cleansed\",\n",
    "    \"f_room_type:f_neighbourhood_cleansed\",\n",
    "    \"n_accommodates:f_neighbourhood_cleansed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_1 = basic_vars\n",
    "predictors_2 = basic_vars + reviews + amenities\n",
    "predictors_E = basic_vars + reviews + amenities + X1 + X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II\n",
    "### RANDOM FORESTS \n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=500,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tune grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid = {\"max_features\": [5, 7, 9], \"min_samples_split\": [6, 11]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all of this to GridSearchCV which will iterate through all combinations of the tunegrid's parameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = GridSearchCV(\n",
    "    rfr, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode data\n",
    "\n",
    "I GOT AN ERROR HERE! HELP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f_room_type', 'f_property_type', 'f_room_type2',\n",
       "       'f_neighbourhood_cleansed', 'usd_price_day', 'p_host_response_rate',\n",
       "       'n_accommodates', 'n_bathrooms', 'n_review_scores_rating',\n",
       "       'n_number_of_reviews',\n",
       "       ...\n",
       "       'flag_review_scores_rating', 'flag_reviews_per_month',\n",
       "       'flag_n_number_of_reviews', 'ln_days_since', 'ln_days_since2',\n",
       "       'ln_days_since3', 'n_days_since2', 'n_days_since3',\n",
       "       'ln_review_scores_rating', 'n_accommodates_copy'],\n",
       "      dtype='object', length=227)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictors_2_cleaned\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Clean column names to remove special characters\n",
    "data_train.columns = data_train.columns.str.replace(r\"[^\\w\\s]\", \"_\", regex=True)\n",
    "\n",
    "# Update predictors_2 to match cleaned column names\n",
    "predictors_2_cleaned = [re.sub(r\"[^\\w\\s]\", \"_\", col) for col in predictors_2]\n",
    "\n",
    "# Ensure the cleaned column names are in the dataframe\n",
    "data_train = data_train.rename(columns=dict(zip(predictors_2, predictors_2_cleaned)))\n",
    "\n",
    "# Create design matrices\n",
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2_cleaned), data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model (**NOTE:** load fitted model below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['f_room_type', 'f_property_type', 'f_room_type2',\n",
      "       'f_neighbourhood_cleansed', 'usd_price_day', 'p_host_response_rate',\n",
      "       'n_accommodates', 'n_bathrooms', 'n_review_scores_rating',\n",
      "       'n_number_of_reviews',\n",
      "       ...\n",
      "       'flag_review_scores_rating', 'flag_reviews_per_month',\n",
      "       'flag_n_number_of_reviews', 'ln_days_since', 'ln_days_since2',\n",
      "       'ln_days_since3', 'n_days_since2', 'n_days_since3',\n",
      "       'ln_review_scores_rating', 'n_accommodates_copy'],\n",
      "      dtype='object', length=227)\n"
     ]
    }
   ],
   "source": [
    "data_train.columns = data_train.columns.astype(str)\n",
    "# Remove unwanted characters\n",
    "data_train = data_train.rename(columns=lambda x: x.replace(\".\", \"_\"))\n",
    "data_train = data_train.rename(columns=lambda x: x.replace(\"-\", \"_\").replace(\" \", \"_\"))\n",
    "data_train = data_train.rename(columns=lambda x: f\"var_{x}\" if x[0].isdigit() else x)\n",
    "data_train.columns = data_train.columns.str.replace(r\"[\\'\\\"]\", \"\", regex=True)  # Remove apostrophes and quotes\n",
    "data_train.columns = data_train.columns.str.replace(r\"[^a-zA-Z0-9_]\", \"_\", regex=True)  # Replace other special characters\n",
    "data_train.columns = [\"var_\" + col if col[0].isdigit() else col for col in data_train.columns]  # Prefix numbers\n",
    "data_train.columns = data_train.columns.str.replace(r\"[^\\w]\", \"_\", regex=True)\n",
    "print(data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_room_type', 'f_property_type', 'f_room_type2', 'f_neighbourhood_cleansed', 'usd_price_day', 'p_host_response_rate', 'n_accommodates', 'n_bathrooms', 'n_review_scores_rating', 'n_number_of_reviews', 'n_reviews_per_month', 'n_minimum_nights', 'n_beds', 'n_days_since', 'd_unnamed_59', 'd_backyard', 'd_baking_sheet', 'd_books_and_reading_material', 'd_breakfast', 'd_carbon_monoxide_alarm', 'd_cleaning_products', 'd_dining_table', 'd_dishes_and_silverware', 'd_dryer', 'd_essentials', 'd_exercise_equipment', 'd_exterior_security_cameras_on_property', 'd_extra_pillows_and_blankets', 'd_fire_extinguisher', 'd_first_aid_kit', 'd_free_street_parking', 'd_freezer', 'd_hangers', 'd_heating', 'd_hockey_rink', 'd_host_greets_you', 'd_hot_tub', 'd_hot_water', 'd_hot_water_kettle', 'd_indoor_fireplace', 'd_iron', 'd_keypad', 'd_kitchen', 'd_lock_on_bedroom_door', 'd_long_term_stays_allowed', 'd_microwave', 'd_noise_decibel_monitors_on_property', 'd_pets_allowed', 'd_ping_pong_table', 'd_pool', 'd_refrigerator', 'd_self_check_in', 'd_shampoo', 'd_shower_gel', 'd_smoking_allowed', 'd_stove', 'd_sun_loungers', 'd_toaster', 'd_tv', 'd_washer', 'd_wifi', 'd_wine_glasses', 'd_contiene_alimentos_nuestros', 'd_body_soap', 'd_conditioner', 'd_2_5_years_old', 'd_3_days_a_week_included_with_your_stay', 'd_5_10_years_old', 'd_and_10_years_old', 'd_and_5_10_years_old', 'd_arcade_games', 'd_barbecue_utensils', 'd_bathtub', 'd_bed_linens', 'd_beko_frigor_fico_nuevo', 'd_bidet', 'd_bikes', 'd_blanca', 'd_blender', 'd_board_games', 'd_boat_slip', 'd_bowling_alley', 'd_bread_maker', 'd_building_staff', 'd_carrefour', 'd_ceiling_fan', 'd_cerave', 'd_champ', 'd_cleaning_available_during_stay', 'd_climbing_wall', 'd_clothing_storage', 'd_coffee_maker', 'd_cooking_basics', 'd_deliplus', 'd_disney', 'd_dove', 'd_dove_hidratante', 'd_dvd_player', 'd_elevator', 'd_es_un_hornillo_peque_o_y_el_ctrico', 'd_ethernet_connection', 'd_every_day', 'd_every_day_included_with_your_stay', 'd_fire_pit', 'd_free_driveway_parking_on_premises', 'd_free_residential_garage_on_premises', 'd_french_press', 'd_friday', 'd_friday_included_with_your_stay', 'd_game_console', 'd_gel', 'd_gel_de_ducha', 'd_gel_familiar', 'd_gym', 'd_hammock', 'd_hbo_max', 'd_hisense', 'd_kayak', 'd_la_marca_puede_variar', 'd_la_toja', 'd_laser_tag', 'd_latoja', 'd_life_size_games', 'd_lockbox', 'd_luggage_dropoff_allowed', 'd_mini_golf', 'd_molton_brown', 'd_monday', 'd_monday_included_with_your_stay', 'd_monday_to_friday_included_with_your_stay', 'd_monday_to_tuesday_included_with_your_stay', 'd_mosquito_net', 'd_movie_theater', 'd_natural_honery', 'd_new_pol', 'd_no_tengo_servicio_de_cocina', 'd_nuky', 'd_open_24_hours', 'd_open_specific_hours', 'd_outdoor_pool', 'd_outlet_covers', 'd_oven', 'd_paid_street_parking_off_premises', 'd_peque_o_para_pizza', 'd_pero', 'd_piano', 'd_pool_available_seasonally', 'd_pool_cover', 'd_pool_table', 'd_pool_toys', 'd_portable_fans', 'd_portable_heater', 'd_private_pool', 'd_record_player', 'd_revlon', 'd_rice_maker', 'd_roku', 'd_rooftop', 'd_room_darkening_shades', 'd_rowing', 'd_safe', 'd_saltwater', 'd_saturday_included_with_your_stay', 'd_sauna', 'd_sebamed', 'd_si_nos_lo_pides', 'd_single_level_home', 'd_sink', 'd_skate_ramp', 'd_ski_in_ski_out', 'd_smart_lock', 'd_smoke_alarm', 'd_sonos', 'd_sony_htsf_aux', 'd_sound_system', 'd_sunday', 'd_table_corner_guards', 'd_theme_room', 'd_thursday', 'd_thursday_included_with_your_stay', 'd_tuesday', 'd_tuesday_to_friday_included_with_your_stay', 'd_variada', 'd_variado', 'd_waterfront', 'd_wednesday', 'd_window_guards', 'd_wood_burning', 'd_streaming_services', 'd_child_friendly', 'd_free_parking', 'd_paid_parking', 'd_cable', 'd_view', 'd_balcony', 'd_bbq', 'd_housekeeping_included', 'd_housekeeping_extracost', 'd_paid_dryer_washer', 'd_airconditioning', 'd_electric_car_charging', 'd_indoor_pool', 'd_outdoor_space', 'price', 'host_id', 'neighbourhood_cleansed', 'room_type', 'property_type', 'n_accommodates2', 'ln_accommodates', 'ln_accommodates2', 'ln_beds', 'ln_number_of_reviews', 'f_bathroom', 'f_number_of_reviews', 'f_minimum_nights', 'flag_days_since', 'flag_review_scores_rating', 'flag_reviews_per_month', 'flag_n_number_of_reviews', 'ln_days_since', 'ln_days_since2', 'ln_days_since3', 'n_days_since2', 'n_days_since3', 'ln_review_scores_rating', 'n_accommodates_copy']\n"
     ]
    }
   ],
   "source": [
    "print(data_train.columns.tolist())  # Show all column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END max_features=5, min_samples_split=6;, score=-65.673 total time=   1.3s\n",
      "[CV 2/5] END max_features=5, min_samples_split=6;, score=-66.374 total time=   1.3s\n",
      "[CV 3/5] END max_features=5, min_samples_split=6;, score=-74.241 total time=   1.3s\n",
      "[CV 4/5] END max_features=5, min_samples_split=6;, score=-70.403 total time=   1.3s\n",
      "[CV 5/5] END max_features=5, min_samples_split=6;, score=-67.677 total time=   1.3s\n",
      "[CV 1/5] END max_features=5, min_samples_split=11;, score=-66.825 total time=   1.3s\n",
      "[CV 2/5] END max_features=5, min_samples_split=11;, score=-67.471 total time=   1.5s\n",
      "[CV 3/5] END max_features=5, min_samples_split=11;, score=-75.585 total time=   1.4s\n",
      "[CV 4/5] END max_features=5, min_samples_split=11;, score=-71.640 total time=   1.5s\n",
      "[CV 5/5] END max_features=5, min_samples_split=11;, score=-69.287 total time=   1.5s\n",
      "[CV 1/5] END max_features=7, min_samples_split=6;, score=-65.254 total time=   1.5s\n",
      "[CV 2/5] END max_features=7, min_samples_split=6;, score=-65.867 total time=   1.6s\n",
      "[CV 3/5] END max_features=7, min_samples_split=6;, score=-73.339 total time=   1.4s\n",
      "[CV 4/5] END max_features=7, min_samples_split=6;, score=-69.860 total time=   1.4s\n",
      "[CV 5/5] END max_features=7, min_samples_split=6;, score=-67.183 total time=   1.4s\n",
      "[CV 1/5] END max_features=7, min_samples_split=11;, score=-66.507 total time=   1.6s\n",
      "[CV 2/5] END max_features=7, min_samples_split=11;, score=-66.765 total time=   1.7s\n",
      "[CV 3/5] END max_features=7, min_samples_split=11;, score=-75.054 total time=   1.4s\n",
      "[CV 4/5] END max_features=7, min_samples_split=11;, score=-71.109 total time=   1.7s\n",
      "[CV 5/5] END max_features=7, min_samples_split=11;, score=-68.407 total time=   1.5s\n",
      "[CV 1/5] END max_features=9, min_samples_split=6;, score=-64.994 total time=   1.5s\n",
      "[CV 2/5] END max_features=9, min_samples_split=6;, score=-65.676 total time=   1.4s\n",
      "[CV 3/5] END max_features=9, min_samples_split=6;, score=-73.191 total time=   1.4s\n",
      "[CV 4/5] END max_features=9, min_samples_split=6;, score=-69.598 total time=   1.5s\n",
      "[CV 5/5] END max_features=9, min_samples_split=6;, score=-66.994 total time=   1.5s\n",
      "[CV 1/5] END max_features=9, min_samples_split=11;, score=-66.103 total time=   1.4s\n",
      "[CV 2/5] END max_features=9, min_samples_split=11;, score=-66.378 total time=   1.5s\n",
      "[CV 3/5] END max_features=9, min_samples_split=11;, score=-74.443 total time=   1.4s\n",
      "[CV 4/5] END max_features=9, min_samples_split=11;, score=-70.609 total time=   1.4s\n",
      "[CV 5/5] END max_features=9, min_samples_split=11;, score=-68.157 total time=   1.5s\n"
     ]
    }
   ],
   "source": [
    "rf_model_1 = rf_random.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_model_1, open(\"model_fits/random_forest.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_1 = pickle.load(open(\"model_fits/random_forest.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the above steps in one cell, for a bit complicate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This took around 3 minutes on a 2020 M1 Macbook Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=500,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "tune_grid = {\n",
    "    \"max_features\": [8, 10, 12],\n",
    "    \"min_samples_split\": [6, 11, 16],\n",
    "}\n",
    "\n",
    "rf_random = GridSearchCV(\n",
    "    rfr, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=3\n",
    ")\n",
    "\n",
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n",
    "\n",
    "rf_model_2 = rf_random.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_model_2, open(\"model_fits/random_forest_broad.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2 = pickle.load(open(\"model_fits/random_forest_broad.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate models\n",
    "\n",
    "Test set performance within the workout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE test\": [\n",
    "                rf_model_1.cv_results_[\"mean_test_score\"].min(),\n",
    "                rf_model_2.cv_results_[\"mean_test_score\"].min(),\n",
    "            ]\n",
    "        },\n",
    "        [\"Model 1\", \"Model 2\"],\n",
    "    )\n",
    "    * -1\n",
    ")\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART III\n",
    "### MODEL DIAGNOSTICS \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data for model diagnostics from fitted GridSearchCV objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2_var_imp_df = (\n",
    "    pd.DataFrame(\n",
    "        rf_model_2.best_estimator_.feature_importances_, X.design_info.column_names\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename({\"index\": \"varname\", 0: \"imp\"}, axis=1)\n",
    "    .assign(\n",
    "        imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum(),\n",
    "        varname=lambda x: x.varname.str.replace(\n",
    "            \"f_room_type[T.\", \"Room type:\", regex=False\n",
    "        )\n",
    "        .str.replace(\"f_neighbourhood_cleansed[T.\", \"Borough:\", regex=False)\n",
    "        .str.replace(\"]\", \"\", regex=False),\n",
    "    )\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) full varimp plot, above a cutoff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.013\n",
    "\n",
    "rf_model_2_var_imp_plot = (\n",
    "    ggplot(\n",
    "        rf_model_2_var_imp_df.loc[lambda x: x.imp > cutoff],\n",
    "        aes(x=\"reorder(varname, imp)\", y=\"imp_percentage\"),\n",
    "    )\n",
    "    + geom_point(color=\"blue\", size=2.5)\n",
    "    + geom_segment(\n",
    "        aes(x=\"varname\", xend=\"varname\", y=0, yend=\"imp_percentage\"),\n",
    "        color=\"blue\",\n",
    "        size=2\n",
    "    )\n",
    "    + ylab(\"Importance (Percent)\")\n",
    "    + xlab(\"Variable Name\")\n",
    "    + coord_flip()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_bw()\n",
    ")\n",
    "rf_model_2_var_imp_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) full varimp plot, top 10 only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        rf_model_2_var_imp_df.iloc[:10, :],\n",
    "        aes(x=\"reorder(varname, imp)\", y=\"imp_percentage\"),\n",
    "    )\n",
    "    + geom_point(color=\"blue\", size=2.5)\n",
    "    + geom_segment(\n",
    "        aes(x=\"varname\", xend=\"varname\", y=0, yend=\"imp_percentage\"),\n",
    "        color=\"blue\",\n",
    "        size=2,\n",
    "    )\n",
    "    + ylab(\"Importance (Percent)\")\n",
    "    + xlab(\"Variable Name\")\n",
    "    + coord_flip()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) grouped variable importance - keep binaries created off factors together**\n",
    "\n",
    "For this, you need to create an sklearn pipeline and put OneHotEncoding in it (before, encoding was done by patsy's dmatrices). This way permutation_importance can calculate factor variables' importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_best_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocess\", preprocessing),\n",
    "        (\"regressor\", rf_model_2.best_estimator_),  # put best model to pipeline\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline.fit(data_train[predictors_2], data_train.price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a while – So we saved the results, you can load it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    rf_best_pipeline,\n",
    "    data_train[predictors_2],\n",
    "    data_train[\"price\"],\n",
    "    n_repeats=10,\n",
    "    random_state=45,\n",
    "    n_jobs=-1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(result, open(\"model_fits/random_forest_permutation_importance.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pickle.load(open(\"model_fits/random_forest_permutation_importance.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_imp = (\n",
    "    pd.DataFrame(result.importances_mean, data_train[predictors_2].columns)\n",
    "    .reset_index()\n",
    "    .rename({\"index\": \"varname\", 0: \"imp\"}, axis=1)\n",
    "    .assign(imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum())\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        grouped_imp.head(15),\n",
    "        aes(x=\"reorder(varname, imp)\", y=\"imp_percentage\"),\n",
    "    )\n",
    "    + geom_point(color=\"blue\", size=2.5)\n",
    "    + geom_segment(\n",
    "        aes(x=\"varname\", xend=\"varname\", y=0, yend=\"imp_percentage\"),\n",
    "        color=\"blue\",\n",
    "        size=2,\n",
    "    )\n",
    "    + ylab(\"Importance (Percent)\")\n",
    "    + xlab(\"Variable Name\")\n",
    "    + coord_flip()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots \n",
    "-------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: we do this on holdout set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(\n",
    "    rf_best_pipeline,\n",
    "    data_holdout[predictors_2],\n",
    "    [\"n_accommodates\"],\n",
    "    feature_names=data_holdout[predictors_2].columns,\n",
    "    line_kw={\"marker\": \"o\", \"color\": \"blue\"},\n",
    ")\n",
    "plt.grid()\n",
    "plt.ylim(70, 130)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical features, this is a bit complicated, first extract pdp values with `partial_dependence`, then do the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomtype_pdp = partial_dependence(\n",
    "    rf_best_pipeline, data_holdout[predictors_2], [\"f_room_type\"], kind=\"average\"\n",
    ")\n",
    "\n",
    "roomtype_pdp = (\n",
    "    pd.DataFrame(roomtype_pdp[\"average\"], columns=roomtype_pdp[\"values\"][0].tolist())\n",
    "    .T.reset_index()\n",
    "    .rename({0: \"Predicted price\", \"index\": \"Room type\"}, axis=1)\n",
    ")\n",
    "\n",
    "(\n",
    "    ggplot(roomtype_pdp, aes(x=\"Room type\", y=\"Predicted price\"))\n",
    "    + geom_point(color=\"blue\", size=2)\n",
    "    + scale_y_continuous(limits=[60, 120], breaks=np.arange(60, 121, 10))\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample performance: RMSE / mean(y) \n",
    "---------------------------------------\n",
    "NOTE  we do this on the holdout set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predicted values on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holdout_w_prediction = data_holdout.assign(\n",
    "    predicted_price=rf_best_pipeline.predict(data_holdout[predictors_2])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nice summary table of heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(groupby_obj):\n",
    "    return (\n",
    "        groupby_obj.apply(\n",
    "            lambda x: mean_squared_error(x.predicted_price, x.price, squared=False),\n",
    "        )\n",
    "        .to_frame(name=\"rmse\")\n",
    "        .assign(mean_price=groupby_obj.apply(lambda x: np.mean(x.price)).values)\n",
    "        .assign(rmse_norm=lambda x: x.rmse / x.mean_price)\n",
    "        .round(2)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheaper or more expensive flats - not used in book\n",
    "grouped_object = data_holdout_w_prediction.assign(\n",
    "    is_low_size=lambda x: np.where(x.n_accommodates <= 3, \"small apt\", \"large apt\")\n",
    ").groupby(\"is_low_size\")\n",
    "accom_subset = calculate_rmse(grouped_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_object = data_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_neighbourhood_cleansed.isin(\n",
    "        [\n",
    "            \"Westminster\",\n",
    "            \"Camden\",\n",
    "            \"Kensington and Chelsea\",\n",
    "            \"Tower Hamlets\",\n",
    "            \"Hackney\",\n",
    "            \"Newham\",\n",
    "        ]\n",
    "    )\n",
    "].groupby(\"f_neighbourhood_cleansed\")\n",
    "neightbourhood_subset = calculate_rmse(grouped_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_object = data_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_property_type.isin([\"Apartment\", \"House\"])\n",
    "].groupby(\"f_property_type\")\n",
    "proptype_subset = calculate_rmse(grouped_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holdout = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            mean_squared_error(\n",
    "                data_holdout_w_prediction.price,\n",
    "                data_holdout_w_prediction.predicted_price,\n",
    "                squared=False,\n",
    "            ),\n",
    "            data_holdout_w_prediction.price.mean(),\n",
    "        ],\n",
    "        index=[\"rmse\", \"mean_price\"],\n",
    "    )\n",
    "    .T.assign(rmse_norm=lambda x: x.rmse / x.mean_price)\n",
    "    .round(2)\n",
    ")\n",
    "all_holdout.index = [\"All\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_rows = pd.DataFrame(\n",
    "    None,\n",
    "    index=[\"Apartment size\", \"Type\", \"Borough\"],\n",
    "    columns=[\"rmse\", \"mean_price\", \"rmse_norm\"],\n",
    ").fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 16.2 Performance across subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        type_rows.iloc[[0]],\n",
    "        accom_subset,\n",
    "        type_rows.iloc[[1]],\n",
    "        proptype_subset,\n",
    "        type_rows.iloc[[2]],\n",
    "        neightbourhood_subset,\n",
    "        all_holdout,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP Explainer takes an encoded matrix as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline[\"preprocess\"].fit(data_holdout.filter(predictors_2))\n",
    "\n",
    "# transform categorical features\n",
    "X_encoded = rf_best_pipeline[\"preprocess\"].transform(\n",
    "    data_holdout.filter(predictors_2)\n",
    ")\n",
    "new_feature_names = rf_best_pipeline[\"preprocess\"].get_feature_names()\n",
    "X_holdout = pd.DataFrame(X_encoded, columns=new_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SHAP values for our best model\n",
    "\n",
    "**NOTE:** Again, we do this on the holdout set!\n",
    "\n",
    "Run time, around 50 minutes is on a 2020 M1 Macbook Pro with Monterery 12.6. To decrease run time, you can decrease the number of estimators (now 500) in the random forest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_best_pipeline[\"regressor\"].predict, X_holdout)\n",
    "shap_values = explainer(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(explainer, open(\"model_fits/shap_values.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = pickle.load(open(\"model_fits/shap_values.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can do the same with log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display = 15, log_scale = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in absolute values – see similarities with simple variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values.abs, color=\"shap_red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for observation predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple bar of SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfall plot\n",
    "The waterfall plot has the same information, represented in a different manner. Here we can see how the sum of all the SHAP values equals the difference between the prediction $f(x)$ and the expected value $E[f(x)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate RF models on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_holdout = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance = pd.DataFrame(\n",
    "    {\n",
    "        \"Simple Random Forest\": rmse(\n",
    "            rf_model_1.predict(X_holdout), data_holdout[\"price\"]\n",
    "        ),\n",
    "        \"Broad Random Forest\": rmse(\n",
    "            rf_best_pipeline.predict(data_holdout[predictors_2]), data_holdout[\"price\"]\n",
    "        ),\n",
    "    },\n",
    "    index=[\"holdout RMSE\"],\n",
    ").T\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART IV\n",
    "### HORSERACE: compare with other models \n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. OLS with dummies for area\n",
    "\n",
    " using model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n",
    "\n",
    "ols_model = LinearRegression().fit(X, y)\n",
    "\n",
    "holdout_performance.loc[\"OLS\"] = rmse(\n",
    "    ols_model.predict(X_holdout).ravel(), data_holdout[\"price\"]\n",
    ")\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model_coeffs_df = pd.DataFrame(\n",
    "    ols_model.coef_.tolist()[0],\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"ols_coefficient\"],\n",
    ").assign(ols_coefficient=lambda x: x.ols_coefficient.round(3))\n",
    "ols_model_coeffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  LASSO\n",
    "\n",
    "using extended model w interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable, unless you supply your own sequence of alpha.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = ElasticNet(l1_ratio=1, normalize=True, fit_intercept=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_cv = GridSearchCV(\n",
    "    lasso_model,\n",
    "    {\"alpha\": [i / 100 for i in range(1, 26, 1)]},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_E), data_train)\n",
    "_, X_holdout_lasso = dmatrices(\"price ~ \" + \" + \".join(predictors_E), data_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_model_cv.fit(X, y.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"LASSO\"] = rmse(\n",
    "    lasso_model_cv.predict(X_holdout_lasso), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-zero coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    lasso_model_cv.best_estimator_.coef_.tolist(),\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"lasso_coefficient\"],\n",
    ").assign(lasso_coefficient=lambda x: x.lasso_coefficient.round(3)).loc[\n",
    "    lambda x: x.lasso_coefficient != 0\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeClassifier(random_state=2018, criterion=\"gini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get potential ccp_alpha, regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = cart_model.cost_complexity_pruning_path(X, y.ravel())\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random search to select a \"best\" alpha\n",
    " \n",
    "    \n",
    " RandomizedSearchCV does not calculate all potential alphas, just a random subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cart_model_cv = RandomizedSearchCV(\n",
    "    cart_model,\n",
    "    {\"ccp_alpha\": ccp_alphas},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "\n",
    "cart_model_cv.fit(X, y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"CART\"] = rmse(\n",
    "    cart_model_cv.predict(X_holdout), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm = XGBRegressor(learning_rate=0.1)\n",
    "\n",
    "tune_grid = {\"n_estimators\": [i for i in range(200, 500, 50)], \"max_depth\": [1, 5, 10]}\n",
    "\n",
    "xgbm_model_cv = GridSearchCV(\n",
    "    xgbm, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=10, n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgbm_pipe = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", xgbm_model_cv)], verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This takes a while, you can import the fitted model below.\n",
    "\n",
    "Run time (8.3 minutes) is on a 2020 M1 Macbook Pro with Monterery 12.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe.fit(data_train[predictors_2], data_train.price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbm_pipe,open('model_fits/xgb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Load the fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe = pickle.load(open(\"model_fits/xgb.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"XGBoost\"] = rmse(\n",
    "    xgbm_pipe.predict(data_holdout[predictors_2]), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next will be in final model, loads of tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_broad = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid = {\n",
    "    \"n_estimators\": [i for i in range(50, 500, 50)],\n",
    "    \"max_depth\": [1, 5, 10],\n",
    "    \"learning_rate\": [0.02, 0.05, 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "xgbm_model_cv_broad = GridSearchCV(\n",
    "    xgbm_broad,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgbm_pipe_broad = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", xgbm_model_cv_broad)], verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run time (47.3 minutes) is on a 2020 M1 Macbook Pro with Monterery 12.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbm_pipe_broad.fit(data_train[predictors_2], data_train.price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbm_pipe_broad, open(\"model_fits/xgb_broad.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Load the fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe_broad = pickle.load(open(\"model_fits/xgb_broad.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"XGBoost broad\"] = rmse(\n",
    "    xgbm_pipe_broad.predict(data_holdout[predictors_2]), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performing model is the broadly tuned Random Forest\n",
    "\n",
    "Interesting, that the broadly tuning model resulted in the same model as the simple tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe_broad[\"regressor\"].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe[\"regressor\"].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to access all details on each hyperparameter combination (sorted by performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgbm_pipe_broad[\"regressor\"].cv_results_).sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
