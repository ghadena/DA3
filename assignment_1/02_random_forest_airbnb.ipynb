{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Random Forest      \n",
    "                                     \n",
    "Topics covered:                     \n",
    "   - Data cleaning & refactoring & feature engineering in a separate file            \n",
    "   - Run random forest  \n",
    "     - set mytr                      \n",
    "     - autotune                       \n",
    "   - Understanding RF output:        \n",
    "     - variable importance plots:    \n",
    "       - all, top 10 and permutation importance for categorical features      \n",
    "     - partial dependence plot       \n",
    "     - sub-sample analysis    \n",
    "     - SHAP values\n",
    "   - \"Horse-race\": model comparison  \n",
    "     - OLS, Lasso, CART, RF and XGBoost model          \n",
    "                                \n",
    "Case studies:                  \n",
    "  - CH16A Predicting apartment prices with random forest  \n",
    "                                \n",
    "Dataset:\n",
    "\n",
    "    airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from mizani.formatters import percent_format\n",
    "from patsy import dmatrices\n",
    "from plotnine import *\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import (\n",
    "    partial_dependence,\n",
    "    permutation_importance,\n",
    "    plot_partial_dependence,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I\n",
    "### Loading and preparing data \n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/airbnb_london_workfile_adj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample definition and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on normal apartments, n<8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[lambda x: x[\"n_accommodates\"] < 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy a variable - purpose later, see at variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(n_accommodates_copy=data.n_accommodates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.f_room_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.f_property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.f_number_of_reviews.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and holdout samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is where we do it all, incl CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_holdout = train_test_split(data, train_size=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.shape, data_holdout.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Variables inc neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_vars = [\n",
    "    \"n_accommodates\",\n",
    "    \"n_beds\",\n",
    "    \"n_days_since\",\n",
    "    \"f_property_type\",\n",
    "    \"f_room_type\",\n",
    "    \"f_bathroom\",\n",
    "    \"f_cancellation_policy\",\n",
    "    \"f_bed_type\",\n",
    "    \"f_neighbourhood_cleansed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"n_number_of_reviews\",\n",
    "    \"flag_n_number_of_reviews\",\n",
    "    \"n_review_scores_rating\",\n",
    "    \"flag_review_scores_rating\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = [col for col in data if col.startswith(\"d_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions for the LASSO from lecture 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [\n",
    "    \"n_accommodates:f_property_type\",\n",
    "    \"f_room_type:f_property_type\",\n",
    "    \"f_room_type:d_familykidfriendly\",\n",
    "    \"d_airconditioning:f_property_type\",\n",
    "    \"d_cats:f_property_type\",\n",
    "    \"d_dogs:f_property_type\",\n",
    "]\n",
    "# with boroughs\n",
    "X2 = [\n",
    "    \"f_property_type:f_neighbourhood_cleansed\",\n",
    "    \"f_room_type:f_neighbourhood_cleansed\",\n",
    "    \"n_accommodates:f_neighbourhood_cleansed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_1 = basic_vars\n",
    "predictors_2 = basic_vars + reviews + amenities\n",
    "predictors_E = basic_vars + reviews + amenities + X1 + X2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II\n",
    "### RANDOM FORESTS \n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=500,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define tune grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid = {\"max_features\": [5, 7, 9], \"min_samples_split\": [6, 11]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all of this to GridSearchCV which will iterate through all combinations of the tunegrid's parameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = GridSearchCV(\n",
    "    rfr, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model (**NOTE:** load fitted model below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_1 = rf_random.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_model_1, open(\"model_fits/random_forest.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_1 = pickle.load(open(\"model_fits/random_forest.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the above steps in one cell, for a bit complicate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This took around 3 minutes on a 2020 M1 Macbook Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    criterion=\"squared_error\",\n",
    "    n_estimators=500,\n",
    "    oob_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "tune_grid = {\n",
    "    \"max_features\": [8, 10, 12],\n",
    "    \"min_samples_split\": [6, 11, 16],\n",
    "}\n",
    "\n",
    "rf_random = GridSearchCV(\n",
    "    rfr, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=3\n",
    ")\n",
    "\n",
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n",
    "\n",
    "rf_model_2 = rf_random.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_model_2, open(\"model_fits/random_forest_broad.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2 = pickle.load(open(\"model_fits/random_forest_broad.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate models\n",
    "\n",
    "Test set performance within the workout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE test\": [\n",
    "                rf_model_1.cv_results_[\"mean_test_score\"].min(),\n",
    "                rf_model_2.cv_results_[\"mean_test_score\"].min(),\n",
    "            ]\n",
    "        },\n",
    "        [\"Model 1\", \"Model 2\"],\n",
    "    )\n",
    "    * -1\n",
    ")\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART III\n",
    "### MODEL DIAGNOSTICS \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data for model diagnostics from fitted GridSearchCV objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2_var_imp_df = (\n",
    "    pd.DataFrame(\n",
    "        rf_model_2.best_estimator_.feature_importances_, X.design_info.column_names\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename({\"index\": \"varname\", 0: \"imp\"}, axis=1)\n",
    "    .assign(\n",
    "        imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum(),\n",
    "        varname=lambda x: x.varname.str.replace(\n",
    "            \"f_room_type[T.\", \"Room type:\", regex=False\n",
    "        )\n",
    "        .str.replace(\"f_neighbourhood_cleansed[T.\", \"Borough:\", regex=False)\n",
    "        .str.replace(\"]\", \"\", regex=False),\n",
    "    )\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) full varimp plot, above a cutoff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.013\n",
    "\n",
    "rf_model_2_var_imp_plot = (\n",
    "    ggplot(\n",
    "        rf_model_2_var_imp_df.loc[lambda x: x.imp > cutoff],\n",
    "        aes(x=\"reorder(varname, imp)\", y=\"imp_percentage\"),\n",
    "    )\n",
    "    + geom_point(color=\"blue\", size=2.5)\n",
    "    + geom_segment(\n",
    "        aes(x=\"varname\", xend=\"varname\", y=0, yend=\"imp_percentage\"),\n",
    "        color=\"blue\",\n",
    "        size=2\n",
    "    )\n",
    "    + ylab(\"Importance (Percent)\")\n",
    "    + xlab(\"Variable Name\")\n",
    "    + coord_flip()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_bw()\n",
    ")\n",
    "rf_model_2_var_imp_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) full varimp plot, top 10 only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        rf_model_2_var_imp_df.iloc[:10, :],\n",
    "        aes(x=\"reorder(varname, imp)\", y=\"imp_percentage\"),\n",
    "    )\n",
    "    + geom_point(color=\"blue\", size=2.5)\n",
    "    + geom_segment(\n",
    "        aes(x=\"varname\", xend=\"varname\", y=0, yend=\"imp_percentage\"),\n",
    "        color=\"blue\",\n",
    "        size=2,\n",
    "    )\n",
    "    + ylab(\"Importance (Percent)\")\n",
    "    + xlab(\"Variable Name\")\n",
    "    + coord_flip()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) grouped variable importance - keep binaries created off factors together**\n",
    "\n",
    "For this, you need to create an sklearn pipeline and put OneHotEncoding in it (before, encoding was done by patsy's dmatrices). This way permutation_importance can calculate factor variables' importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_best_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocess\", preprocessing),\n",
    "        (\"regressor\", rf_model_2.best_estimator_),  # put best model to pipeline\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline.fit(data_train[predictors_2], data_train.price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a while – So we saved the results, you can load it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    rf_best_pipeline,\n",
    "    data_train[predictors_2],\n",
    "    data_train[\"price\"],\n",
    "    n_repeats=10,\n",
    "    random_state=45,\n",
    "    n_jobs=-1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(result, open(\"model_fits/random_forest_permutation_importance.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pickle.load(open(\"model_fits/random_forest_permutation_importance.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_imp = (\n",
    "    pd.DataFrame(result.importances_mean, data_train[predictors_2].columns)\n",
    "    .reset_index()\n",
    "    .rename({\"index\": \"varname\", 0: \"imp\"}, axis=1)\n",
    "    .assign(imp_percentage=lambda x: x[\"imp\"] / x[\"imp\"].sum())\n",
    "    .sort_values(by=[\"imp\"], ascending=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        grouped_imp.head(15),\n",
    "        aes(x=\"reorder(varname, imp)\", y=\"imp_percentage\"),\n",
    "    )\n",
    "    + geom_point(color=\"blue\", size=2.5)\n",
    "    + geom_segment(\n",
    "        aes(x=\"varname\", xend=\"varname\", y=0, yend=\"imp_percentage\"),\n",
    "        color=\"blue\",\n",
    "        size=2,\n",
    "    )\n",
    "    + ylab(\"Importance (Percent)\")\n",
    "    + xlab(\"Variable Name\")\n",
    "    + coord_flip()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence Plots \n",
    "-------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note: we do this on holdout set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(\n",
    "    rf_best_pipeline,\n",
    "    data_holdout[predictors_2],\n",
    "    [\"n_accommodates\"],\n",
    "    feature_names=data_holdout[predictors_2].columns,\n",
    "    line_kw={\"marker\": \"o\", \"color\": \"blue\"},\n",
    ")\n",
    "plt.grid()\n",
    "plt.ylim(70, 130)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical features, this is a bit complicated, first extract pdp values with `partial_dependence`, then do the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomtype_pdp = partial_dependence(\n",
    "    rf_best_pipeline, data_holdout[predictors_2], [\"f_room_type\"], kind=\"average\"\n",
    ")\n",
    "\n",
    "roomtype_pdp = (\n",
    "    pd.DataFrame(roomtype_pdp[\"average\"], columns=roomtype_pdp[\"values\"][0].tolist())\n",
    "    .T.reset_index()\n",
    "    .rename({0: \"Predicted price\", \"index\": \"Room type\"}, axis=1)\n",
    ")\n",
    "\n",
    "(\n",
    "    ggplot(roomtype_pdp, aes(x=\"Room type\", y=\"Predicted price\"))\n",
    "    + geom_point(color=\"blue\", size=2)\n",
    "    + scale_y_continuous(limits=[60, 120], breaks=np.arange(60, 121, 10))\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsample performance: RMSE / mean(y) \n",
    "---------------------------------------\n",
    "NOTE  we do this on the holdout set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save predicted values on holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holdout_w_prediction = data_holdout.assign(\n",
    "    predicted_price=rf_best_pipeline.predict(data_holdout[predictors_2])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nice summary table of heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(groupby_obj):\n",
    "    return (\n",
    "        groupby_obj.apply(\n",
    "            lambda x: mean_squared_error(x.predicted_price, x.price, squared=False),\n",
    "        )\n",
    "        .to_frame(name=\"rmse\")\n",
    "        .assign(mean_price=groupby_obj.apply(lambda x: np.mean(x.price)).values)\n",
    "        .assign(rmse_norm=lambda x: x.rmse / x.mean_price)\n",
    "        .round(2)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheaper or more expensive flats - not used in book\n",
    "grouped_object = data_holdout_w_prediction.assign(\n",
    "    is_low_size=lambda x: np.where(x.n_accommodates <= 3, \"small apt\", \"large apt\")\n",
    ").groupby(\"is_low_size\")\n",
    "accom_subset = calculate_rmse(grouped_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_object = data_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_neighbourhood_cleansed.isin(\n",
    "        [\n",
    "            \"Westminster\",\n",
    "            \"Camden\",\n",
    "            \"Kensington and Chelsea\",\n",
    "            \"Tower Hamlets\",\n",
    "            \"Hackney\",\n",
    "            \"Newham\",\n",
    "        ]\n",
    "    )\n",
    "].groupby(\"f_neighbourhood_cleansed\")\n",
    "neightbourhood_subset = calculate_rmse(grouped_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_object = data_holdout_w_prediction.loc[\n",
    "    lambda x: x.f_property_type.isin([\"Apartment\", \"House\"])\n",
    "].groupby(\"f_property_type\")\n",
    "proptype_subset = calculate_rmse(grouped_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_holdout = (\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            mean_squared_error(\n",
    "                data_holdout_w_prediction.price,\n",
    "                data_holdout_w_prediction.predicted_price,\n",
    "                squared=False,\n",
    "            ),\n",
    "            data_holdout_w_prediction.price.mean(),\n",
    "        ],\n",
    "        index=[\"rmse\", \"mean_price\"],\n",
    "    )\n",
    "    .T.assign(rmse_norm=lambda x: x.rmse / x.mean_price)\n",
    "    .round(2)\n",
    ")\n",
    "all_holdout.index = [\"All\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_rows = pd.DataFrame(\n",
    "    None,\n",
    "    index=[\"Apartment size\", \"Type\", \"Borough\"],\n",
    "    columns=[\"rmse\", \"mean_price\", \"rmse_norm\"],\n",
    ").fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 16.2 Performance across subsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        type_rows.iloc[[0]],\n",
    "        accom_subset,\n",
    "        type_rows.iloc[[1]],\n",
    "        proptype_subset,\n",
    "        type_rows.iloc[[2]],\n",
    "        neightbourhood_subset,\n",
    "        all_holdout,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP Explainer takes an encoded matrix as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_pipeline[\"preprocess\"].fit(data_holdout.filter(predictors_2))\n",
    "\n",
    "# transform categorical features\n",
    "X_encoded = rf_best_pipeline[\"preprocess\"].transform(\n",
    "    data_holdout.filter(predictors_2)\n",
    ")\n",
    "new_feature_names = rf_best_pipeline[\"preprocess\"].get_feature_names()\n",
    "X_holdout = pd.DataFrame(X_encoded, columns=new_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SHAP values for our best model\n",
    "\n",
    "**NOTE:** Again, we do this on the holdout set!\n",
    "\n",
    "Run time, around 50 minutes is on a 2020 M1 Macbook Pro with Monterery 12.6. To decrease run time, you can decrease the number of estimators (now 500) in the random forest object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_best_pipeline[\"regressor\"].predict, X_holdout)\n",
    "shap_values = explainer(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(explainer, open(\"model_fits/shap_values.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = pickle.load(open(\"model_fits/shap_values.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can do the same with log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, max_display = 15, log_scale = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in absolute values – see similarities with simple variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values.abs, color=\"shap_red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for observation predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple bar of SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfall plot\n",
    "The waterfall plot has the same information, represented in a different manner. Here we can see how the sum of all the SHAP values equals the difference between the prediction $f(x)$ and the expected value $E[f(x)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate RF models on the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_holdout = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance = pd.DataFrame(\n",
    "    {\n",
    "        \"Simple Random Forest\": rmse(\n",
    "            rf_model_1.predict(X_holdout), data_holdout[\"price\"]\n",
    "        ),\n",
    "        \"Broad Random Forest\": rmse(\n",
    "            rf_best_pipeline.predict(data_holdout[predictors_2]), data_holdout[\"price\"]\n",
    "        ),\n",
    "    },\n",
    "    index=[\"holdout RMSE\"],\n",
    ").T\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART IV\n",
    "### HORSERACE: compare with other models \n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. OLS with dummies for area\n",
    "\n",
    " using model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n",
    "\n",
    "ols_model = LinearRegression().fit(X, y)\n",
    "\n",
    "holdout_performance.loc[\"OLS\"] = rmse(\n",
    "    ols_model.predict(X_holdout).ravel(), data_holdout[\"price\"]\n",
    ")\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model_coeffs_df = pd.DataFrame(\n",
    "    ols_model.coef_.tolist()[0],\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"ols_coefficient\"],\n",
    ").assign(ols_coefficient=lambda x: x.ols_coefficient.round(3))\n",
    "ols_model_coeffs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  LASSO\n",
    "\n",
    "using extended model w interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio = 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable, unless you supply your own sequence of alpha.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = ElasticNet(l1_ratio=1, normalize=True, fit_intercept=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_cv = GridSearchCV(\n",
    "    lasso_model,\n",
    "    {\"alpha\": [i / 100 for i in range(1, 26, 1)]},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_E), data_train)\n",
    "_, X_holdout_lasso = dmatrices(\"price ~ \" + \" + \".join(predictors_E), data_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso_model_cv.fit(X, y.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"LASSO\"] = rmse(\n",
    "    lasso_model_cv.predict(X_holdout_lasso), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-zero coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    lasso_model_cv.best_estimator_.coef_.tolist(),\n",
    "    index=X.design_info.column_names,\n",
    "    columns=[\"lasso_coefficient\"],\n",
    ").assign(lasso_coefficient=lambda x: x.lasso_coefficient.round(3)).loc[\n",
    "    lambda x: x.lasso_coefficient != 0\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices(\"price ~ \" + \" + \".join(predictors_2), data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_model = DecisionTreeClassifier(random_state=2018, criterion=\"gini\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get potential ccp_alpha, regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = cart_model.cost_complexity_pruning_path(X, y.ravel())\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random search to select a \"best\" alpha\n",
    " \n",
    "    \n",
    " RandomizedSearchCV does not calculate all potential alphas, just a random subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cart_model_cv = RandomizedSearchCV(\n",
    "    cart_model,\n",
    "    {\"ccp_alpha\": ccp_alphas},\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "\n",
    "cart_model_cv.fit(X, y.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"CART\"] = rmse(\n",
    "    cart_model_cv.predict(X_holdout), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm = XGBRegressor(learning_rate=0.1)\n",
    "\n",
    "tune_grid = {\"n_estimators\": [i for i in range(200, 500, 50)], \"max_depth\": [1, 5, 10]}\n",
    "\n",
    "xgbm_model_cv = GridSearchCV(\n",
    "    xgbm, tune_grid, cv=5, scoring=\"neg_root_mean_squared_error\", verbose=10, n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgbm_pipe = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", xgbm_model_cv)], verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This takes a while, you can import the fitted model below.\n",
    "\n",
    "Run time (8.3 minutes) is on a 2020 M1 Macbook Pro with Monterery 12.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe.fit(data_train[predictors_2], data_train.price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbm_pipe,open('model_fits/xgb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Load the fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe = pickle.load(open(\"model_fits/xgb.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"XGBoost\"] = rmse(\n",
    "    xgbm_pipe.predict(data_holdout[predictors_2]), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next will be in final model, loads of tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_broad = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_grid = {\n",
    "    \"n_estimators\": [i for i in range(50, 500, 50)],\n",
    "    \"max_depth\": [1, 5, 10],\n",
    "    \"learning_rate\": [0.02, 0.05, 0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "xgbm_model_cv_broad = GridSearchCV(\n",
    "    xgbm_broad,\n",
    "    tune_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    verbose=10,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [col for col in predictors_2 if col.startswith(\"f_\")]\n",
    "numerical_columns = [col for col in predictors_2 if col not in categorical_columns]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    [\n",
    "        (\"cat\", categorical_encoder, categorical_columns),\n",
    "        (\"num\", \"passthrough\", numerical_columns),\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgbm_pipe_broad = Pipeline(\n",
    "    [(\"preprocess\", preprocessing), (\"regressor\", xgbm_model_cv_broad)], verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run time (47.3 minutes) is on a 2020 M1 Macbook Pro with Monterery 12.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbm_pipe_broad.fit(data_train[predictors_2], data_train.price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgbm_pipe_broad, open(\"model_fits/xgb_broad.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Load the fitted model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe_broad = pickle.load(open(\"model_fits/xgb_broad.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_performance.loc[\"XGBoost broad\"] = rmse(\n",
    "    xgbm_pipe_broad.predict(data_holdout[predictors_2]), data_holdout[\"price\"]\n",
    ")\n",
    "\n",
    "holdout_performance.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performing model is the broadly tuned Random Forest\n",
    "\n",
    "Interesting, that the broadly tuning model resulted in the same model as the simple tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe_broad[\"regressor\"].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm_pipe[\"regressor\"].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to access all details on each hyperparameter combination (sorted by performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgbm_pipe_broad[\"regressor\"].cv_results_).sort_values(by=[\"rank_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c01754e8627d0ea60fdf9a984fbf743943cf4db47884120dd04bfc512143b077"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
